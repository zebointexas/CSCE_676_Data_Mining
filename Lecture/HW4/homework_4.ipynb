{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCE 676 :: Data Mining and Analysis :: Texas A&M University :: Fall 2019\n",
    "\n",
    "\n",
    "# Homework 4\n",
    "\n",
    "- **100 points [5% of your final grade]**\n",
    "- **Due December 1 by 11:59pm**\n",
    "\n",
    "*Submission instructions:* You should post your notebook to ecampus (look for the homework 4 assignment there). Please name your submission **your-uin_hw4.ipynb**, so for example, my submission would be something like **555001234_hw4.ipynb**. Your notebook should be fully executed when you submit ... so run all the cells for us so we can see the output, then submit that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (40 points) Part 1: Bloom Filters\n",
    "\n",
    "For this first part, you are provided a csv file containig around 1 million of user-movie-rating interactions (already sorted by timestamp). You should implement the Counting Bloom Filter algorithm, which stores counts rather then binary indocators in the hash table so that the algorithm can handle deletions.\n",
    "\n",
    "In your implementation, use the movieId as the key k for the hash function, and the hash function as h_i(k) = ((k % m) + 2^i) % m, where h_i(k) is the i-th hash function, i starts from 0 to r-1, r is the number of hash functions, m is the size of the hash table. Implement your Counting Bloom Filter as a class with r and m as two variables that will be set values when the class is instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we provide the class to read data from MovieLens_rating.csv. Run the cell below before you continue the homework, which will instanciate a variable dataStream, and you will use it to read data in the following questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataStream():\n",
    "    def __init__(self):\n",
    "        self._df = pd.read_csv('./MovieLens_ratings.csv')\n",
    "        self._pointer = -1\n",
    "        \n",
    "    def read_one(self):\n",
    "        self._pointer += 1\n",
    "        if self._pointer < len(self._df):\n",
    "            return {'userId': self._df.at[self._pointer, 'userId'], \n",
    "                    'movieId': self._df.at[self._pointer, 'movieId']}\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def reset(self):\n",
    "        self._pointer = -1\n",
    "\n",
    "dataStream = DataStream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After run the above cell, now you need to call dataStream.read_one() for 300,000 times to read in 300,000 records, and maintain one Counting Bloom Filter. Here, set the number of hash functions as 10, and the hash table size as 500.\n",
    "\n",
    "**!!NOTE!! You should have a loop for 300,000 times, and in each iteration, call dataStream.read_one() first, then update your filter based on the current data sample.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read 100,000 records more, and for each of them, check whether the movie has already been seen during the first 300,000 records based on your Counting Bloom Filter. Output the number of records whose movies are seen before, and the number of records whose movies are not seen before. (During this process, do not update the filter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# print two numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, read 100,000 records more, and for each of them, check if the movie is in the filter or not, if it is, then delete the movie from the filter, otherwise do nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, read 100,000 records more, and for each of them, check whether the movie is in the filter or not. Output the number of records whose movies are seen before, and the number of records whose movies are not seen before. (During this process, do not update the filter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# print two numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go to the next part, let's reset the dataStream and repeat the above process to explore the impact of r and m. You need to call dataStream.reset() to reset the reader, then call dataStream.read_one() for 300,000 times and build your filter. Then, call dataStream.read_one() for another 300,000 times, and for each of the data sample, check whether the movie is in the first 300,000 records or not based on your filter, and report the False Positive Rate. Try different r and m, **plot figures (one or two)** to show how false positive rate changes with different r and m, and **report the best pair of parameters** you think and **discuss why**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataStream.reset()\n",
    "# your code here\n",
    "# plot figure(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Put your discussion here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (30 points) Part 2: Determine approximately the top-5 movies\n",
    "\n",
    "In this part, you need to first reset the dataStream, then read the whole file by dataStream.read_one() util it returns None. You need to implement the reservoir sampling algorithm to determine approximately the top-5 most frequent movies. \n",
    "\n",
    "First you need to implement a function add_reservoir(reservoir, movieId, max_size) that adds a movie to the reservoir, maintaining its size. If the reservoir is already of size max_size, a random movie is selected and evicted before adding the new movie. It is important to evict an old movie before adding the new item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_to_reservoir(reservoir, movieId, max_reservoir_size):\n",
    "    # YOUR CODE HERE\n",
    "    assert(len(reservoir) <= max_reservoir_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the file using the reservoir sampling method with maximum size of 1,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataStream.reset()\n",
    "reservoir_size = 1000\n",
    "reservoir = []\n",
    "\n",
    "i = 0\n",
    "dataSample = dataStream.read_one()\n",
    "while not dataSample == None:\n",
    "    i += 1\n",
    "    # YOUR CODE HERE\n",
    "        \n",
    "print(\"Number of records seen    : %d\" % i)\n",
    "print(\"Number of records sampled : %d\" % len(reservoir) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to list the top-5 most frequent movies found by looking at frequencies in the reservoir. If you see a movie C times in the reservoir, you can estimate the query appears C x N / reservoir_size times in the actual sample. **You need to join the resulting top-5 movie ids with the file movies.dat to show the top-5 movies by their names.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dataStream._df to get the DataFrame variable of the whole MovieLens_ratings.csv, and compute the top-5 most frequent movies by the dataframe. Compare with the approximating results by reservoir sampling algorithm, **discuss your observations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Put your discussion here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, repeat the process above and try different reservoir_size, compare the correpsonding results with ground truth, **report the best parameter you think** and **discuss the reason**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Put your discussion here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (30 points) Part 3: Determine approximately the number of users.\n",
    "\n",
    "In this part, you need to estimate the number of distinct users without creating a hash table with users, but instead, you should use the Flajolet-Martin probabilistic counting method.\n",
    "\n",
    "First you need to reset dataStream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataStream.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to count trailing zeroes in the binary representation of a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_trailing_zeroes(number):\n",
    "    count = 0\n",
    "    while number & 1 == 0:\n",
    "        count += 1\n",
    "        number = number >> 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function below to generate a random hash function. Note this generates a function, so you can do hash_function = random_hash_function() and then call hash_function(x) to compute the hash value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_hash_function():\n",
    "    salt = random.random()\n",
    "    return lambda string: hash(string + str(salt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement your Flajolet-Martin probabilistic counting algorithm and perform 10 passes over the file, create a new hash function and use it to hash userids. Keep the maximum number of trailing zeroes seen in the hash value of a userid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_passes = 10\n",
    "\n",
    "estimates = []\n",
    "\n",
    "for i in range(number_of_passes):\n",
    "    # YOUR_CODE_HERE\n",
    "    estimates.append(estimate)\n",
    "    print(\"Estimate on pass %d: %d\" % (i+1, estimate))\n",
    "    \n",
    "print(\"* Average of estimates: %.4f\" % np.mean(estimates))\n",
    "print(\"* Median  of estimates: %.4f\" % np.median(estimates))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
